{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r DATA\n",
    "!unzip /content/drive/MyDrive/drowsyiness.zip -d ./DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to your original dataset directory\n",
    "original_data_folder = './DATA'\n",
    "\n",
    "# Define the path to the new dataset directory where resized images will be saved\n",
    "resized_data_folder = './Resized_DATA'\n",
    "\n",
    "# Define the target size for resizing\n",
    "target_height = 224\n",
    "target_width = 224\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Load the pre-trained Haar Cascade Classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    " \n",
    "\n",
    "def crop_faces_and_save(input_folder, output_folder, target_size=(227, 227)):\n",
    "    # Iterate through each image in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):  # Check if the file is an image\n",
    "            # Load an image\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    " \n",
    "\n",
    "            # Convert the image to grayscale (Haar Cascade works on grayscale images)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    " \n",
    "\n",
    "            # Detect faces in the grayscale image\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    " \n",
    "\n",
    "            # Create output folder if it doesn't exist\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    " \n",
    "\n",
    "            # Crop and save each detected face\n",
    "            for i, (x, y, w, h) in enumerate(faces):\n",
    "                face = image[y:y+h, x:x+w]\n",
    "\n",
    " \n",
    "\n",
    "                # Resize the face to the target size\n",
    "                resized_face = cv2.resize(face, target_size)\n",
    "\n",
    " \n",
    "\n",
    "                output_path = os.path.join(output_folder, f'face_{i}_{filename}')\n",
    "                cv2.imwrite(output_path, resized_face)\n",
    "\n",
    " \n",
    "\n",
    "# Process drowsy images\n",
    "drowsy_input_folder = './DATA/drowsy'\n",
    "drowsy_output_folder = './RESIZED/drowsy'\n",
    "crop_faces_and_save(drowsy_input_folder, drowsy_output_folder)\n",
    "\n",
    " \n",
    "\n",
    "# Process non-drowsy images\n",
    "non_drowsy_input_folder = './DATA/not-drowsy'\n",
    "non_drowsy_output_folder = './RESIZED/notdrowsy'\n",
    "crop_faces_and_save(non_drowsy_input_folder, non_drowsy_output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the path to your dataset directory\n",
    "data_folder = './RESIZED'\n",
    "\n",
    "# Define data generators for training and validation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # If you want to split data into training and validation sets\n",
    ")\n",
    "\n",
    "# Load and preprocess the data\n",
    "batch_size = 32\n",
    "img_height = 227  # Adjust as per your image size\n",
    "img_width = 227   # Adjust as per your image size\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_folder,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',  # Use 'binary' for two classes: 'Drowsy' and 'Non-Drowsy'\n",
    "    subset='training',    # Use 'validation' if you have a validation split\n",
    "    classes=['drowsy', 'notdrowsy']\n",
    ")\n",
    "\n",
    "# Create a validation generator\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_folder,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation',  # Use 'training' if you have a training split\n",
    "    classes=['drowsy', 'notdrowsy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer with one neuron for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10  # You can adjust the number of epochs\n",
    "history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loss, validation_accuracy = model.evaluate(validation_generator)\n",
    "print(f'Validation accuracy: {validation_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('drowsiness_detection_model_rnn.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
